"""
RAG Service å•å…ƒæµ‹è¯•
"""

import pytest
from unittest.mock import Mock, patch, MagicMock, AsyncMock
import numpy as np
from datetime import datetime
import tempfile
import os

from services.rag_service import rag_service

# æµ‹è¯•æ•°æ®
MOCK_DOCUMENT_TEXT = """
è½¯ä»¶æ¶æ„æ˜¯ç³»ç»Ÿçš„æ ¹æœ¬ç»„ç»‡ç»“æ„ï¼Œå®ƒå®šä¹‰äº†ç³»ç»Ÿçš„å„ä¸ªç»„ä»¶ã€ç»„ä»¶ä¹‹é—´çš„å…³ç³»ä»¥åŠæŒ‡å¯¼å…¶è®¾è®¡å’Œæ¼”åŒ–çš„åŸåˆ™å’Œå‡†åˆ™ã€‚

è½¯ä»¶æ¶æ„çš„é‡è¦æ€§ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
1. æä¾›ç³»ç»Ÿçš„æ•´ä½“è§†å›¾
2. æ”¯æŒç³»ç»Ÿè´¨é‡å±æ€§
3. ä¾¿äºå›¢é˜Ÿåä½œ
4. æ”¯æŒç³»ç»Ÿæ¼”åŒ–

å¸¸è§çš„æ¶æ„æ¨¡å¼åŒ…æ‹¬ï¼š
- åˆ†å±‚æ¶æ„
- å¾®æœåŠ¡æ¶æ„
- äº‹ä»¶é©±åŠ¨æ¶æ„
- é¢†åŸŸé©±åŠ¨è®¾è®¡
"""

MOCK_CHUNKS = [
    {
        "id": "chunk_1",
        "content": "è½¯ä»¶æ¶æ„æ˜¯ç³»ç»Ÿçš„æ ¹æœ¬ç»„ç»‡ç»“æ„ï¼Œå®ƒå®šä¹‰äº†ç³»ç»Ÿçš„å„ä¸ªç»„ä»¶ã€ç»„ä»¶ä¹‹é—´çš„å…³ç³»ä»¥åŠæŒ‡å¯¼å…¶è®¾è®¡å’Œæ¼”åŒ–çš„åŸåˆ™å’Œå‡†åˆ™ã€‚",
        "metadata": {"source": "test_doc.md", "chunk_index": 0},
        "embedding": [0.1, 0.2, 0.3, 0.4, 0.5]
    },
    {
        "id": "chunk_2", 
        "content": "è½¯ä»¶æ¶æ„çš„é‡è¦æ€§ä½“ç°åœ¨æä¾›ç³»ç»Ÿçš„æ•´ä½“è§†å›¾ã€æ”¯æŒç³»ç»Ÿè´¨é‡å±æ€§ã€ä¾¿äºå›¢é˜Ÿåä½œã€æ”¯æŒç³»ç»Ÿæ¼”åŒ–ç­‰æ–¹é¢ã€‚",
        "metadata": {"source": "test_doc.md", "chunk_index": 1},
        "embedding": [0.2, 0.3, 0.4, 0.5, 0.6]
    }
]

MOCK_QUERY_EMBEDDING = [0.15, 0.25, 0.35, 0.45, 0.55]

MOCK_SEARCH_RESULTS = [
    {
        "content": "è½¯ä»¶æ¶æ„æ˜¯ç³»ç»Ÿçš„æ ¹æœ¬ç»„ç»‡ç»“æ„ï¼Œå®ƒå®šä¹‰äº†ç³»ç»Ÿçš„å„ä¸ªç»„ä»¶ã€ç»„ä»¶ä¹‹é—´çš„å…³ç³»ä»¥åŠæŒ‡å¯¼å…¶è®¾è®¡å’Œæ¼”åŒ–çš„åŸåˆ™å’Œå‡†åˆ™ã€‚",
        "metadata": {"source": "test_doc.md", "chunk_index": 0},
        "similarity": 0.95
    },
    {
        "content": "è½¯ä»¶æ¶æ„çš„é‡è¦æ€§ä½“ç°åœ¨æä¾›ç³»ç»Ÿçš„æ•´ä½“è§†å›¾ã€æ”¯æŒç³»ç»Ÿè´¨é‡å±æ€§ã€ä¾¿äºå›¢é˜Ÿåä½œã€æ”¯æŒç³»ç»Ÿæ¼”åŒ–ç­‰æ–¹é¢ã€‚",
        "metadata": {"source": "test_doc.md", "chunk_index": 1},
        "similarity": 0.87
    }
]

class TestRAGService:
    """RAGæœåŠ¡æµ‹è¯•ç±»"""
    
    def test_rag_service_initialization(self):
        """æµ‹è¯•RAGæœåŠ¡åˆå§‹åŒ–"""
        assert rag_service is not None
        assert hasattr(rag_service, 'embedding_model')
        assert hasattr(rag_service, 'vector_store')
        assert hasattr(rag_service, 'chunk_size')
        assert hasattr(rag_service, 'chunk_overlap')
    
    def test_text_splitting(self):
        """æµ‹è¯•æ–‡æœ¬åˆ†å‰²åŠŸèƒ½"""
        long_text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬ã€‚" * 100  # æ¨¡æ‹Ÿé•¿æ–‡æœ¬
        
        chunks = rag_service.split_text(long_text, chunk_size=100, chunk_overlap=20)
        
        assert len(chunks) > 1
        assert all(isinstance(chunk, str) for chunk in chunks)
        assert all(len(chunk) <= 120 for chunk in chunks)  # è€ƒè™‘overlap
    
    def test_text_splitting_empty_input(self):
        """æµ‹è¯•ç©ºè¾“å…¥çš„æ–‡æœ¬åˆ†å‰²"""
        chunks = rag_service.split_text("", chunk_size=100)
        assert chunks == []
        
        chunks = rag_service.split_text(None, chunk_size=100)
        assert chunks == []
    
    @patch('services.rag_service.SentenceTransformer')
    def test_generate_embeddings_success(self, mock_sentence_transformer):
        """æµ‹è¯•ç”ŸæˆåµŒå…¥å‘é‡ - æˆåŠŸ"""
        # Mockæ¨¡å‹
        mock_model = MagicMock()
        mock_model.encode.return_value = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])
        mock_sentence_transformer.return_value = mock_model
        
        # é‡æ–°åˆå§‹åŒ–æœåŠ¡ä»¥ä½¿ç”¨mockæ¨¡å‹
        rag_service._init_embedding_model()
        
        texts = ["æ–‡æœ¬1", "æ–‡æœ¬2"]
        embeddings = rag_service.generate_embeddings(texts)
        
        assert len(embeddings) == 2
        assert len(embeddings[0]) == 3
        assert isinstance(embeddings, list)
        mock_model.encode.assert_called_once_with(texts, convert_to_tensor=False)
    
    @patch('services.rag_service.SentenceTransformer')
    def test_generate_embeddings_empty_input(self, mock_sentence_transformer):
        """æµ‹è¯•ç”ŸæˆåµŒå…¥å‘é‡ - ç©ºè¾“å…¥"""
        mock_model = MagicMock()
        mock_model.encode.return_value = np.array([])
        mock_sentence_transformer.return_value = mock_model
        
        rag_service._init_embedding_model()
        
        embeddings = rag_service.generate_embeddings([])
        assert embeddings == []
        
        embeddings = rag_service.generate_embeddings([""])
        assert len(embeddings) == 1
    
    @patch('services.rag_service.get_db')
    def test_add_document_success(self, mock_get_db):
        """æµ‹è¯•æ·»åŠ æ–‡æ¡£ - æˆåŠŸ"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        with patch.object(rag_service, 'split_text') as mock_split, \
             patch.object(rag_service, 'generate_embeddings') as mock_embeddings, \
             patch('services.rag_service.DocumentChunk') as mock_chunk_model:
            
            # è®¾ç½®mockè¿”å›å€¼
            mock_split.return_value = ["chunk1", "chunk2"]
            mock_embeddings.return_value = [[0.1, 0.2], [0.3, 0.4]]
            
            mock_chunk = MagicMock()
            mock_chunk_model.return_value = mock_chunk
            
            result = rag_service.add_document(
                content=MOCK_DOCUMENT_TEXT,
                metadata={"source": "test.md", "title": "æµ‹è¯•æ–‡æ¡£"}
            )
            
            assert result["status"] == "success"
            assert result["chunks_created"] == 2
            assert "document_id" in result
            
            # éªŒè¯æ•°æ®åº“æ“ä½œ
            assert mock_db.add.call_count == 2  # ä¸¤ä¸ªchunk
            mock_db.commit.assert_called_once()
    
    @patch('services.rag_service.get_db')
    def test_add_document_empty_content(self, mock_get_db):
        """æµ‹è¯•æ·»åŠ æ–‡æ¡£ - ç©ºå†…å®¹"""
        result = rag_service.add_document(content="", metadata={})
        
        assert result["status"] == "error"
        assert "æ–‡æ¡£å†…å®¹ä¸èƒ½ä¸ºç©º" in result["message"]
    
    @patch('services.rag_service.get_db')
    def test_search_similar_chunks_success(self, mock_get_db):
        """æµ‹è¯•æœç´¢ç›¸ä¼¼ç‰‡æ®µ - æˆåŠŸ"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        # Mockæ•°æ®åº“æŸ¥è¯¢ç»“æœ
        mock_chunks = [
            MagicMock(
                content=MOCK_CHUNKS[0]["content"],
                metadata=MOCK_CHUNKS[0]["metadata"],
                embedding=MOCK_CHUNKS[0]["embedding"]
            ),
            MagicMock(
                content=MOCK_CHUNKS[1]["content"],
                metadata=MOCK_CHUNKS[1]["metadata"],
                embedding=MOCK_CHUNKS[1]["embedding"]
            )
        ]
        mock_db.query.return_value.all.return_value = mock_chunks
        
        with patch.object(rag_service, 'generate_embeddings') as mock_embeddings:
            mock_embeddings.return_value = [MOCK_QUERY_EMBEDDING]
            
            results = rag_service.search_similar_chunks(
                query="ä»€ä¹ˆæ˜¯è½¯ä»¶æ¶æ„ï¼Ÿ",
                top_k=2,
                similarity_threshold=0.8
            )
            
            assert len(results) == 2
            assert all("content" in result for result in results)
            assert all("metadata" in result for result in results)
            assert all("similarity" in result for result in results)
            assert all(result["similarity"] >= 0.8 for result in results)
    
    @patch('services.rag_service.get_db')
    def test_search_similar_chunks_no_results(self, mock_get_db):
        """æµ‹è¯•æœç´¢ç›¸ä¼¼ç‰‡æ®µ - æ— ç»“æœ"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        mock_db.query.return_value.all.return_value = []
        
        with patch.object(rag_service, 'generate_embeddings') as mock_embeddings:
            mock_embeddings.return_value = [MOCK_QUERY_EMBEDDING]
            
            results = rag_service.search_similar_chunks(
                query="ä¸ç›¸å…³çš„æŸ¥è¯¢",
                top_k=5
            )
            
            assert results == []
    
    def test_calculate_cosine_similarity(self):
        """æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—"""
        vec1 = [1, 0, 0]
        vec2 = [0, 1, 0]
        vec3 = [1, 0, 0]
        
        similarity_orthogonal = rag_service._calculate_cosine_similarity(vec1, vec2)
        similarity_identical = rag_service._calculate_cosine_similarity(vec1, vec3)
        
        assert abs(similarity_orthogonal - 0.0) < 1e-10  # å‚ç›´å‘é‡ç›¸ä¼¼åº¦ä¸º0
        assert abs(similarity_identical - 1.0) < 1e-10   # ç›¸åŒå‘é‡ç›¸ä¼¼åº¦ä¸º1
    
    def test_calculate_cosine_similarity_edge_cases(self):
        """æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—è¾¹ç•Œæƒ…å†µ"""
        # é›¶å‘é‡
        zero_vec = [0, 0, 0]
        normal_vec = [1, 1, 1]
        
        similarity = rag_service._calculate_cosine_similarity(zero_vec, normal_vec)
        assert similarity == 0.0
        
        # ç©ºå‘é‡
        similarity = rag_service._calculate_cosine_similarity([], [])
        assert similarity == 0.0
    
    @patch('services.rag_service.get_db')
    def test_delete_document_success(self, mock_get_db):
        """æµ‹è¯•åˆ é™¤æ–‡æ¡£ - æˆåŠŸ"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        # MockæŸ¥è¯¢ç»“æœ
        mock_chunks = [MagicMock(), MagicMock()]
        mock_db.query.return_value.filter.return_value.all.return_value = mock_chunks
        
        result = rag_service.delete_document("test_doc_id")
        
        assert result["status"] == "success"
        assert result["deleted_chunks"] == 2
        
        # éªŒè¯åˆ é™¤æ“ä½œ
        for chunk in mock_chunks:
            mock_db.delete.assert_any_call(chunk)
        mock_db.commit.assert_called_once()
    
    @patch('services.rag_service.get_db')
    def test_delete_document_not_found(self, mock_get_db):
        """æµ‹è¯•åˆ é™¤æ–‡æ¡£ - æ–‡æ¡£ä¸å­˜åœ¨"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        mock_db.query.return_value.filter.return_value.all.return_value = []
        
        result = rag_service.delete_document("nonexistent_doc_id")
        
        assert result["status"] == "error"
        assert "æ–‡æ¡£æœªæ‰¾åˆ°" in result["message"]
    
    @patch('services.rag_service.get_db')
    def test_get_document_stats(self, mock_get_db):
        """æµ‹è¯•è·å–æ–‡æ¡£ç»Ÿè®¡"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        # Mockç»Ÿè®¡æŸ¥è¯¢
        mock_db.query.return_value.count.return_value = 150  # æ€»chunkæ•°
        mock_db.query.return_value.distinct.return_value.count.return_value = 25  # æ–‡æ¡£æ•°
        
        # Mockæ–‡æ¡£æºç»Ÿè®¡
        mock_sources = [("doc1.md", 10), ("doc2.pdf", 20), ("doc3.txt", 15)]
        mock_db.query.return_value.group_by.return_value.all.return_value = mock_sources
        
        stats = rag_service.get_document_stats()
        
        assert stats["total_chunks"] == 150
        assert stats["total_documents"] == 25
        assert stats["sources"] == [
            {"source": "doc1.md", "chunks": 10},
            {"source": "doc2.pdf", "chunks": 20},
            {"source": "doc3.txt", "chunks": 15}
        ]
    
    def test_answer_question_with_context(self):
        """æµ‹è¯•åŸºäºä¸Šä¸‹æ–‡å›ç­”é—®é¢˜"""
        context_chunks = [
            {"content": "è½¯ä»¶æ¶æ„æ˜¯ç³»ç»Ÿçš„æ ¹æœ¬ç»„ç»‡ç»“æ„ã€‚", "similarity": 0.95},
            {"content": "å®ƒå®šä¹‰äº†ç³»ç»Ÿçš„å„ä¸ªç»„ä»¶å’Œç»„ä»¶ä¹‹é—´çš„å…³ç³»ã€‚", "similarity": 0.88}
        ]
        
        question = "ä»€ä¹ˆæ˜¯è½¯ä»¶æ¶æ„ï¼Ÿ"
        
        with patch.object(rag_service, 'search_similar_chunks') as mock_search:
            mock_search.return_value = context_chunks
            
            answer = rag_service.answer_question(question, use_ai=False)
            
            assert "è½¯ä»¶æ¶æ„æ˜¯ç³»ç»Ÿçš„æ ¹æœ¬ç»„ç»‡ç»“æ„" in answer["answer"]
            assert answer["confidence"] > 0.8
            assert len(answer["sources"]) == 2
    
    @patch('services.rag_service.get_db')
    def test_batch_add_documents(self, mock_get_db):
        """æµ‹è¯•æ‰¹é‡æ·»åŠ æ–‡æ¡£"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        documents = [
            {"content": "æ–‡æ¡£1å†…å®¹", "metadata": {"source": "doc1.txt"}},
            {"content": "æ–‡æ¡£2å†…å®¹", "metadata": {"source": "doc2.txt"}},
            {"content": "æ–‡æ¡£3å†…å®¹", "metadata": {"source": "doc3.txt"}}
        ]
        
        with patch.object(rag_service, 'add_document') as mock_add_doc:
            mock_add_doc.return_value = {"status": "success", "chunks_created": 2}
            
            results = rag_service.batch_add_documents(documents)
            
            assert results["total_documents"] == 3
            assert results["successful_documents"] == 3
            assert results["failed_documents"] == 0
            assert mock_add_doc.call_count == 3
    
    @patch('services.rag_service.get_db')
    def test_update_document_success(self, mock_get_db):
        """æµ‹è¯•æ›´æ–°æ–‡æ¡£ - æˆåŠŸ"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        with patch.object(rag_service, 'delete_document') as mock_delete, \
             patch.object(rag_service, 'add_document') as mock_add:
            
            mock_delete.return_value = {"status": "success", "deleted_chunks": 3}
            mock_add.return_value = {"status": "success", "chunks_created": 4, "document_id": "new_doc_id"}
            
            result = rag_service.update_document(
                document_id="old_doc_id",
                new_content="æ–°çš„æ–‡æ¡£å†…å®¹",
                new_metadata={"source": "updated_doc.txt"}
            )
            
            assert result["status"] == "success"
            assert result["old_chunks_deleted"] == 3
            assert result["new_chunks_created"] == 4
            assert result["new_document_id"] == "new_doc_id"


class TestRAGServiceIntegration:
    """RAGæœåŠ¡é›†æˆæµ‹è¯•"""
    
    @patch('services.rag_service.get_db')
    def test_complete_rag_workflow(self, mock_get_db):
        """æµ‹è¯•å®Œæ•´çš„RAGå·¥ä½œæµ"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        with patch.object(rag_service, 'split_text') as mock_split, \
             patch.object(rag_service, 'generate_embeddings') as mock_embeddings, \
             patch('services.rag_service.DocumentChunk') as mock_chunk_model:
            
            # 1. æ·»åŠ æ–‡æ¡£
            mock_split.return_value = ["chunk1", "chunk2"]
            mock_embeddings.return_value = [[0.1, 0.2], [0.3, 0.4]]
            mock_chunk_model.return_value = MagicMock()
            
            add_result = rag_service.add_document(
                content=MOCK_DOCUMENT_TEXT,
                metadata={"source": "test.md"}
            )
            assert add_result["status"] == "success"
            
            # 2. æœç´¢ç›¸ä¼¼å†…å®¹
            mock_chunks = [
                MagicMock(
                    content="è½¯ä»¶æ¶æ„æ˜¯ç³»ç»Ÿçš„æ ¹æœ¬ç»„ç»‡ç»“æ„",
                    metadata={"source": "test.md"},
                    embedding=[0.1, 0.2, 0.3]
                )
            ]
            mock_db.query.return_value.all.return_value = mock_chunks
            mock_embeddings.return_value = [[0.1, 0.2, 0.3]]
            
            search_results = rag_service.search_similar_chunks("ä»€ä¹ˆæ˜¯è½¯ä»¶æ¶æ„ï¼Ÿ")
            assert len(search_results) == 1
            
            # 3. å›ç­”é—®é¢˜
            answer = rag_service.answer_question("ä»€ä¹ˆæ˜¯è½¯ä»¶æ¶æ„ï¼Ÿ", use_ai=False)
            assert "è½¯ä»¶æ¶æ„" in answer["answer"]
            
            # 4. åˆ é™¤æ–‡æ¡£
            mock_db.query.return_value.filter.return_value.all.return_value = mock_chunks
            delete_result = rag_service.delete_document("test_doc_id")
            assert delete_result["status"] == "success"
    
    def test_document_processing_pipeline(self):
        """æµ‹è¯•æ–‡æ¡£å¤„ç†ç®¡é“"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write(MOCK_DOCUMENT_TEXT)
            temp_file_path = f.name
        
        try:
            # æµ‹è¯•æ–‡ä»¶å¤„ç†
            with patch.object(rag_service, 'add_document') as mock_add_doc:
                mock_add_doc.return_value = {"status": "success", "chunks_created": 3}
                
                # æ¨¡æ‹Ÿä»æ–‡ä»¶è¯»å–å†…å®¹
                with open(temp_file_path, 'r', encoding='utf-8') as file:
                    content = file.read()
                
                result = rag_service.add_document(
                    content=content,
                    metadata={"source": temp_file_path, "file_type": "text"}
                )
                
                assert result["status"] == "success"
                mock_add_doc.assert_called_once()
        finally:
            os.unlink(temp_file_path)


class TestRAGServiceValidation:
    """RAGæœåŠ¡éªŒè¯æµ‹è¯•"""
    
    def test_chunk_size_validation(self):
        """æµ‹è¯•chunkå¤§å°éªŒè¯"""
        text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ã€‚" * 10
        
        # æµ‹è¯•æœ€å°chunkå¤§å°
        chunks = rag_service.split_text(text, chunk_size=10)
        assert all(len(chunk) >= 10 for chunk in chunks if chunk.strip())
        
        # æµ‹è¯•æœ€å¤§chunkå¤§å°
        chunks = rag_service.split_text(text, chunk_size=1000)
        assert all(len(chunk) <= 1000 for chunk in chunks)
    
    def test_embedding_dimension_consistency(self):
        """æµ‹è¯•åµŒå…¥å‘é‡ç»´åº¦ä¸€è‡´æ€§"""
        with patch.object(rag_service, 'generate_embeddings') as mock_embeddings:
            # æ¨¡æ‹Ÿä¸åŒæ–‡æœ¬çš„åµŒå…¥å‘é‡éƒ½æœ‰ç›¸åŒç»´åº¦
            mock_embeddings.side_effect = [
                [[0.1, 0.2, 0.3]],  # ç¬¬ä¸€æ¬¡è°ƒç”¨
                [[0.4, 0.5, 0.6]],  # ç¬¬äºŒæ¬¡è°ƒç”¨
            ]
            
            embeddings1 = rag_service.generate_embeddings(["æ–‡æœ¬1"])
            embeddings2 = rag_service.generate_embeddings(["æ–‡æœ¬2"])
            
            assert len(embeddings1[0]) == len(embeddings2[0])
    
    def test_similarity_threshold_validation(self):
        """æµ‹è¯•ç›¸ä¼¼åº¦é˜ˆå€¼éªŒè¯"""
        with patch('services.rag_service.get_db') as mock_get_db:
            mock_db = MagicMock()
            mock_get_db.return_value = mock_db
            mock_db.query.return_value.all.return_value = []
            
            with patch.object(rag_service, 'generate_embeddings') as mock_embeddings:
                mock_embeddings.return_value = [[0.1, 0.2, 0.3]]
                
                # æµ‹è¯•æœ‰æ•ˆé˜ˆå€¼
                results = rag_service.search_similar_chunks(
                    query="æµ‹è¯•æŸ¥è¯¢",
                    similarity_threshold=0.8
                )
                assert isinstance(results, list)
                
                # æµ‹è¯•è¾¹ç•Œå€¼
                results = rag_service.search_similar_chunks(
                    query="æµ‹è¯•æŸ¥è¯¢",
                    similarity_threshold=0.0
                )
                assert isinstance(results, list)
                
                results = rag_service.search_similar_chunks(
                    query="æµ‹è¯•æŸ¥è¯¢",
                    similarity_threshold=1.0
                )
                assert isinstance(results, list)


class TestRAGServicePerformance:
    """RAGæœåŠ¡æ€§èƒ½æµ‹è¯•"""
    
    @patch('services.rag_service.get_db')
    def test_large_document_processing(self, mock_get_db):
        """æµ‹è¯•å¤§æ–‡æ¡£å¤„ç†æ€§èƒ½"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        # ç”Ÿæˆå¤§æ–‡æ¡£
        large_content = MOCK_DOCUMENT_TEXT * 100  # çº¦10KBå†…å®¹
        
        with patch.object(rag_service, 'split_text') as mock_split, \
             patch.object(rag_service, 'generate_embeddings') as mock_embeddings, \
             patch('services.rag_service.DocumentChunk') as mock_chunk_model:
            
            # æ¨¡æ‹Ÿåˆ†å‰²æˆå¤šä¸ªchunk
            mock_split.return_value = [f"chunk_{i}" for i in range(50)]
            mock_embeddings.return_value = [[0.1, 0.2] for _ in range(50)]
            mock_chunk_model.return_value = MagicMock()
            
            import time
            start_time = time.time()
            
            result = rag_service.add_document(content=large_content, metadata={"source": "large_doc.txt"})
            
            end_time = time.time()
            
            assert result["status"] == "success"
            assert end_time - start_time < 5.0  # åº”è¯¥åœ¨5ç§’å†…å®Œæˆ
    
    @patch('services.rag_service.get_db')
    def test_batch_search_performance(self, mock_get_db):
        """æµ‹è¯•æ‰¹é‡æœç´¢æ€§èƒ½"""
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        # æ¨¡æ‹Ÿå¤§é‡æ–‡æ¡£chunk
        mock_chunks = [
            MagicMock(
                content=f"æµ‹è¯•å†…å®¹ {i}",
                metadata={"source": f"doc_{i}.txt"},
                embedding=[0.1 + i*0.01, 0.2 + i*0.01, 0.3 + i*0.01]
            ) for i in range(1000)
        ]
        mock_db.query.return_value.all.return_value = mock_chunks
        
        with patch.object(rag_service, 'generate_embeddings') as mock_embeddings:
            mock_embeddings.return_value = [[0.5, 0.5, 0.5]]
            
            import time
            start_time = time.time()
            
            results = rag_service.search_similar_chunks(
                query="æµ‹è¯•æŸ¥è¯¢",
                top_k=10,
                similarity_threshold=0.7
            )
            
            end_time = time.time()
            
            assert len(results) <= 10
            assert end_time - start_time < 2.0  # åº”è¯¥åœ¨2ç§’å†…å®Œæˆ


@pytest.fixture
def mock_rag_dependencies():
    """RAGæœåŠ¡ä¾èµ–çš„mock fixture"""
    with patch('services.rag_service.get_db') as mock_get_db, \
         patch('services.rag_service.SentenceTransformer') as mock_transformer:
        
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        mock_model = MagicMock()
        mock_model.encode.return_value = np.array([[0.1, 0.2, 0.3]])
        mock_transformer.return_value = mock_model
        
        yield {
            "db": mock_db,
            "transformer": mock_transformer,
            "model": mock_model
        }


class TestRAGServiceEdgeCases:
    """RAGæœåŠ¡è¾¹ç•Œæƒ…å†µæµ‹è¯•"""
    
    def test_unicode_text_handling(self):
        """æµ‹è¯•Unicodeæ–‡æœ¬å¤„ç†"""
        unicode_text = "è¿™æ˜¯ä¸­æ–‡æµ‹è¯•ã€‚ğŸ‰ This is English. Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙØ§Ø±Ø³ÛŒ í•œê¸€"
        
        chunks = rag_service.split_text(unicode_text, chunk_size=20)
        
        assert len(chunks) > 0
        assert all(isinstance(chunk, str) for chunk in chunks)
        # éªŒè¯Unicodeå­—ç¬¦è¢«æ­£ç¡®ä¿ç•™
        combined_text = "".join(chunks)
        assert "ğŸ‰" in combined_text
        assert "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" in combined_text
    
    def test_very_long_single_line(self):
        """æµ‹è¯•æé•¿å•è¡Œæ–‡æœ¬"""
        very_long_line = "è¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„å•è¡Œæ–‡æœ¬ï¼Œ" * 1000  # çº¦15KBçš„å•è¡Œ
        
        chunks = rag_service.split_text(very_long_line, chunk_size=100)
        
        assert len(chunks) > 1
        assert all(len(chunk) <= 120 for chunk in chunks)  # è€ƒè™‘overlap
    
    @patch('services.rag_service.get_db')
    def test_concurrent_document_additions(self, mock_get_db):
        """æµ‹è¯•å¹¶å‘æ–‡æ¡£æ·»åŠ """
        mock_db = MagicMock()
        mock_get_db.return_value = mock_db
        
        with patch.object(rag_service, 'split_text') as mock_split, \
             patch.object(rag_service, 'generate_embeddings') as mock_embeddings, \
             patch('services.rag_service.DocumentChunk') as mock_chunk_model:
            
            mock_split.return_value = ["chunk1"]
            mock_embeddings.return_value = [[0.1, 0.2]]
            mock_chunk_model.return_value = MagicMock()
            
            # æ¨¡æ‹Ÿå¹¶å‘æ·»åŠ å¤šä¸ªæ–‡æ¡£
            import concurrent.futures
            
            def add_doc(doc_id):
                return rag_service.add_document(
                    content=f"æ–‡æ¡£{doc_id}å†…å®¹",
                    metadata={"source": f"doc_{doc_id}.txt"}
                )
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                futures = [executor.submit(add_doc, i) for i in range(5)]
                results = [future.result() for future in futures]
            
            # éªŒè¯æ‰€æœ‰æ–‡æ¡£éƒ½æˆåŠŸæ·»åŠ 
            assert all(result["status"] == "success" for result in results) 